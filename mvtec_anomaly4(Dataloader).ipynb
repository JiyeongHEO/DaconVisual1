{"cells":[{"cell_type":"markdown","source":["# mvtec_anomaly_dataloader"],"metadata":{"id":"ksqe6vhFjv4P"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"kCIAcX580UgX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721569832290,"user_tz":-540,"elapsed":3262,"user":{"displayName":"h지영","userId":"09931517472368185956"}},"outputId":"178cc784-4a78-4005-b26e-029e400fddb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","path = '/content/gdrive/Othercomputers/내 노트북/Desktop/Dacon/ComputerVIsion'\n","\n","import os\n","os.chdir(path)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"jMI_krt-14A9","executionInfo":{"status":"ok","timestamp":1721569827627,"user_tz":-540,"elapsed":6802,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"outputs":[],"source":["import cv2\n","import random\n","import numpy as np\n","import pandas as pd\n","import os.path as osp\n","import torchvision.transforms as transforms\n","\n","from glob import glob\n","from torch.utils.data import Dataset\n","from torchvision.transforms import functional as F\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ibHSA4Lz191r","executionInfo":{"status":"ok","timestamp":1721569832290,"user_tz":-540,"elapsed":2,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"outputs":[],"source":["class mvtecDatasetPreprocess:\n","    def __init__(self, data_dir, mode='train'):\n","        if mode == 'train':\n","            self.image_paths = glob(osp.join(data_dir, mode, \"*.png\"))\n","            csv_path         = osp.join(data_dir, 'train_df.csv')\n","            self.labels      = self.read_label_csv(csv_path)\n","\n","        elif mode == 'test':\n","            self.image_paths  = glob(osp.join(data_dir, mode, '*.png'))\n","\n","\n","    def read_label_csv(self, csv_path):\n","        train_csv = pd.read_csv(csv_path)\n","\n","        train_labels = train_csv['label']\n","        label_unique = sorted(np.unique(train_labels))\n","        label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n","\n","        train_labels = [label_unique[k] for k in train_labels]\n","\n","        return train_labels\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"FRixla4a2VfI","executionInfo":{"status":"ok","timestamp":1721569832290,"user_tz":-540,"elapsed":1,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"outputs":[],"source":["class mvtecDataset(Dataset):\n","    def __init__(self, image_paths, labels, mode='train'):\n","        self.image_paths = image_paths\n","        self.labels      = labels\n","        self.mode        = mode\n","\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","\n","        image = Image.open(image_path).convert('RGB')\n","\n","        # 데이터 증강\n","        if self.mode=='train':\n","            data_transforms = transforms.Compose([\n","                transforms.RandomHorizontalFlip(),\n","                transforms.RandomVerticalFlip(),\n","                transforms.RandomRotation(45),\n","                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n","                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n","                transforms.RandomResizedCrop(512),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","            image = data_transforms(image)\n","\n","        if self.mode=='test':\n","            pass\n","\n","        label = self.labels[idx]\n","\n","        return image, label\n","\n","\n","    def get_labels(self):\n","        return self.labels"]},{"cell_type":"markdown","source":["# mvtec_anomaly_main.py"],"metadata":{"id":"LHSbfbv6j1MM"}},{"cell_type":"code","source":["!pip install timm\n","!pip install torchsampler"],"metadata":{"id":"jlPXCKfhj5PX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","import os.path as osp\n","sys.path.append(osp.join(os.getcwd(), \"test\"))\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import timm\n","import random\n","import time\n","import torch\n","import torch.nn as nn\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import f1_score\n","from torch.utils.data import DataLoader, Subset\n","from torchsampler.imbalanced import ImbalancedDatasetSampler\n","#from mvtec_anomaly_dataloader import mvtecDatasetPreprocess, mvtecDataset\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime"],"metadata":{"id":"fmD3SFwTk7l3","executionInfo":{"status":"ok","timestamp":1721570209102,"user_tz":-540,"elapsed":4714,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def score_function(real, pred):\n","    score = f1_score(real, pred, average=\"macro\")\n","    return score"],"metadata":{"id":"tOATzirmj7Wj","executionInfo":{"status":"ok","timestamp":1721570203496,"user_tz":-540,"elapsed":565,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class Network(nn.Module):\n","    def __init__(self):\n","        super(Network, self).__init__()\n","        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=88)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"metadata":{"id":"ll6YwPVSj8OM","executionInfo":{"status":"ok","timestamp":1721570212963,"user_tz":-540,"elapsed":590,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def debugging_ImbalancedSampler(label_unique, train_loader, device):\n","    # ImbalancedSampler Debugging ------------------------------------\n","    invert_label_unique = {value:key for key, value in label_unique.items()}\n","    df = pd.read_csv(\"open/train_df.csv\")\n","\n","    for idx, sample_data in enumerate(train_loader):\n","        if idx == 1: break\n","        # print(sample_data)\"\"\n","        x = torch.tensor(sample_data[0], dtype=torch.float32, device=device)\n","        y = torch.tensor(sample_data[1], dtype=torch.long, device=device)\n","\n","        label_names = []\n","        print(f\"{'sampled sample_data label':<30} | {'Total Count'}\")\n","        print(\"-\" * 50)\n","        for sample in y:\n","            sample = sample.item()\n","            label_name = invert_label_unique[sample]\n","            label_names.append(label_name)\n","\n","            sampled_label_cnt = len(df[df['label'] == label_name])\n","            print(f\"{label_name:<30} | {sampled_label_cnt:>10}\")\n","        print(label_names)\n","        print(y)\n","    # ---------------------------------------------------------------------"],"metadata":{"id":"9_ZqD_Nrj-KD","executionInfo":{"status":"ok","timestamp":1721570214704,"user_tz":-540,"elapsed":2,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["current_dir = os.getcwd()\n","print(current_dir)\n","file_path = os.path.join(current_dir, 'open')\n","print(file_path)\n","model_dir = os.path.join(current_dir, 'experiments', 'models')\n","print(f\"Model directory: {model_dir}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAlEe7tkmIki","executionInfo":{"status":"ok","timestamp":1721570557110,"user_tz":-540,"elapsed":576,"user":{"displayName":"h지영","userId":"09931517472368185956"}},"outputId":"3c8879a8-ada4-4824-dca1-842e3810038b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/Othercomputers/내 노트북/Desktop/Dacon/ComputerVIsion\n","/content/gdrive/Othercomputers/내 노트북/Desktop/Dacon/ComputerVIsion/open\n","Model directory: /content/gdrive/Othercomputers/내 노트북/Desktop/Dacon/ComputerVIsion/experiments/models\n"]}]},{"cell_type":"code","source":["# 파라미터 셋팅\n","batch_size = 32\n","num_epochs = 120\n","learning_rate = 1e-3\n","folds = 5\n","\n","# GPU 셋팅\n","if torch.cuda.is_available():\n","    device = torch.device(f'cuda:{0}')\n","    print(\"Use GPU: {} for training\".format(0))\n","else:\n","    device = torch.device('cpu')\n","    print('Use CPU')\n","\n","\n","# data_dir  = osp.join(osp.dirname(__file__), 'open') # NameError: name '__file__' is not defined\n","# model_dir = osp.join(osp.dirname(__file__), 'experiments', 'models')\n","# log_dir   = osp.join(osp.dirname(__file__), 'experiments', 'logs')\n","current_dir = os.getcwd()\n","data_dir  = os.path.join(current_dir, 'open')\n","model_dir = os.path.join(current_dir, 'experiments', 'models')\n","log_dir   = os.path.join(current_dir, 'experiments', 'logs')\n","\n","\n","# 폴더 존재 점검\n","if not osp.exists(model_dir):\n","    os.makedirs(model_dir)\n","if not osp.exists(log_dir):\n","    os.makedirs(log_dir)\n","\n","# 텐서보드 셋팅\n","writer = SummaryWriter(log_dir)\n","\n","# 학습 데이터\n","preprocessor = mvtecDatasetPreprocess(data_dir, mode='train')\n","\n","# # 테스트 데이터\n","# test_dataset = mvtecDataset(data_dir, mode='test')\n","# test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# 교차검증\n","kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state = 1)\n","for fold, (indices_train, indices_valid) in enumerate(kfold.split(preprocessor.image_paths, preprocessor.labels)):\n","    subset_train_image_paths = [preprocessor.image_paths[idx] for idx in indices_train]\n","    subset_train_labels      = [preprocessor.labels[idx] for idx in indices_train]\n","\n","    subset_valid_image_paths = [preprocessor.image_paths[idx] for idx in indices_valid]\n","    subset_valid_labels      = [preprocessor.labels[idx] for idx in indices_valid]\n","\n","    train_subset = mvtecDataset(subset_train_image_paths, subset_train_labels)\n","    valid_subset = mvtecDataset(subset_valid_image_paths, subset_valid_labels)\n","\n","    train_loader  = DataLoader(train_subset, batch_size=batch_size,\n","                                sampler=ImbalancedDatasetSampler(train_subset),\n","                                pin_memory=True,\n","                                num_workers=8)\n","    valid_loader  = DataLoader(valid_subset, batch_size=batch_size,\n","                                shuffle=False,\n","                                pin_memory=True,\n","                                num_workers=8)\n","\n","# 모델 정의\n","model = Network().to(device)\n","\n","# 최적화\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","scaler = torch.cuda.amp.GradScaler()\n","\n","# ------------------------------------ 학습 ------------------------------------\n","total_train_steps   = torch.tensor(len(train_loader), dtype=torch.int32, device=device)\n","total_valid_steps   = torch.tensor(len(valid_loader), dtype=torch.int32, device=device)\n","for epoch in range(num_epochs):\n","    start = time.time()\n","\n","    train_loss = torch.zeros(1,     device=device)\n","    model.train()\n","    for train_step, (sample_image, sample_label) in enumerate(train_loader):\n","        # if train_step > 1: break\n","        start = datetime.now()\n","\n","        optimizer.zero_grad()\n","        sample_image = torch.tensor(sample_image, dtype=torch.float32, device=device)\n","        sample_label = torch.tensor(sample_label, dtype=torch.long,    device=device)\n","\n","        with torch.cuda.amp.autocast():\n","            pred = model(sample_image)\n","            loss = criterion(pred, sample_label)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        train_loss += torch.div(loss, total_train_steps)\n","\n","        \"\"\"\n","        (a1 + a2 + ... + a100) / 100 = 평균\n","        a1/100 + a2/100 + .... + a100/100 = 평균\n","        \"\"\"\n","\n","        elapsed_time = datetime.now() - start\n","        if train_step % 30 == 0:\n","            print(f\"[TRAIN] Elapsed time: {elapsed_time} | Epoch: [{epoch + 1:>4}/{num_epochs}] | step: {train_step+1:>4}/{len(train_loader)} | Train Loss: {train_loss.tolist()[0]:4.4f}\")\n","\n","    # ------------------------------------------------------------------------------\n","\n","    # ------------------------------------ 검증 ------------------------------------\n","    valid_loss    = torch.zeros(1,   device=device)\n","    valid_f1      = 0\n","    valid_f1_list = []\n","    model.eval()\n","    for sample_image, sample_label in valid_loader:\n","        start = datetime.now()\n","\n","        sample_image = torch.tensor(sample_image, dtype=torch.float32, device=device)\n","        sample_label = torch.tensor(sample_label, dtype=torch.long,    device=device)\n","\n","        with torch.no_grad():\n","            with torch.cuda.amp.autocast():\n","                pred = model(sample_image)\n","                loss = criterion(pred, sample_label)\n","\n","        valid_loss += torch.div(loss, total_valid_steps)\n","\n","        valid_pred  = pred.argmax(1).detach().cpu().numpy().tolist()\n","        sample_label = sample_label.detach().cpu().numpy().tolist()\n","\n","        valid_f1 += (f1_score(sample_label, valid_pred, average=\"macro\") / len(valid_loader))\n","        valid_f1_list.append(valid_f1)\n","\n","\n","    if len(valid_f1_list) > 1 and (valid_f1 > max(valid_f1_list[:-1])):\n","        torch.save(model.state_dict(), osp.join(model_dir, f'fold_{fold:02d}-epoch_{epoch:03d}.pth'))\n","\n","    elapsed_time = datetime.now() - start\n","    time_left = ((num_epochs - epoch+1) * elapsed_time.seconds) / 3600\n","    print(f\"[VALID] Time Left: {time_left:4.2f} | Epoch: [{epoch + 1:>4}/{num_epochs}] | Valid Loss: {valid_loss.tolist()[0]:4.4f} | Valid F1: {valid_f1_list[-1]*100:.4f}%\")\n","\n","    # 텐서보드\n","    writer.add_scalar('Loss/Train Loss', train_loss.tolist()[0], global_step=epoch)\n","    writer.add_scalar('Loss/Valid Loss', valid_loss.tolist()[0], global_step=epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wa6ZT8mMkBxq","outputId":"aa1ea1bc-149a-45a3-c50a-7a852635d34a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Use GPU: 0 for training\n","[TRAIN] Elapsed time: 0:00:13.737092 | Epoch: [   1/120] | step:    1/107 | Train Loss: 0.0442\n","[TRAIN] Elapsed time: 0:00:00.702098 | Epoch: [   1/120] | step:   31/107 | Train Loss: 1.3081\n","[TRAIN] Elapsed time: 0:00:00.686015 | Epoch: [   1/120] | step:   61/107 | Train Loss: 2.5318\n","[TRAIN] Elapsed time: 0:00:00.540966 | Epoch: [   1/120] | step:   91/107 | Train Loss: 3.7203\n","[VALID] Time Left: 0.00 | Epoch: [   1/120] | Valid Loss: 4.8768 | Valid F1: 0.3372%\n","[TRAIN] Elapsed time: 0:00:00.787367 | Epoch: [   2/120] | step:    1/107 | Train Loss: 0.0410\n","[TRAIN] Elapsed time: 0:00:00.453855 | Epoch: [   2/120] | step:   31/107 | Train Loss: 1.2067\n","[TRAIN] Elapsed time: 0:00:00.439605 | Epoch: [   2/120] | step:   61/107 | Train Loss: 2.3518\n","[TRAIN] Elapsed time: 0:00:00.686521 | Epoch: [   2/120] | step:   91/107 | Train Loss: 3.4784\n","[VALID] Time Left: 0.00 | Epoch: [   2/120] | Valid Loss: 4.8172 | Valid F1: 0.4456%\n","[TRAIN] Elapsed time: 0:00:00.745673 | Epoch: [   3/120] | step:    1/107 | Train Loss: 0.0365\n","[TRAIN] Elapsed time: 0:00:00.670937 | Epoch: [   3/120] | step:   31/107 | Train Loss: 1.1352\n","[TRAIN] Elapsed time: 0:00:00.478566 | Epoch: [   3/120] | step:   61/107 | Train Loss: 2.2301\n","[TRAIN] Elapsed time: 0:00:00.449280 | Epoch: [   3/120] | step:   91/107 | Train Loss: 3.3078\n","[VALID] Time Left: 0.00 | Epoch: [   3/120] | Valid Loss: 5.2983 | Valid F1: 0.0000%\n","[TRAIN] Elapsed time: 0:00:00.762641 | Epoch: [   4/120] | step:    1/107 | Train Loss: 0.0376\n","[TRAIN] Elapsed time: 0:00:00.406629 | Epoch: [   4/120] | step:   31/107 | Train Loss: 1.1124\n","[TRAIN] Elapsed time: 0:00:00.457022 | Epoch: [   4/120] | step:   61/107 | Train Loss: 2.1666\n","[TRAIN] Elapsed time: 0:00:00.458774 | Epoch: [   4/120] | step:   91/107 | Train Loss: 3.1789\n","[VALID] Time Left: 0.00 | Epoch: [   4/120] | Valid Loss: 4.9220 | Valid F1: 0.0514%\n","[TRAIN] Elapsed time: 0:00:01.050812 | Epoch: [   5/120] | step:    1/107 | Train Loss: 0.0321\n","[TRAIN] Elapsed time: 0:00:00.466347 | Epoch: [   5/120] | step:   31/107 | Train Loss: 1.0471\n","[TRAIN] Elapsed time: 0:00:00.674384 | Epoch: [   5/120] | step:   61/107 | Train Loss: 2.0439\n","[TRAIN] Elapsed time: 0:00:00.693102 | Epoch: [   5/120] | step:   91/107 | Train Loss: 3.0293\n","[VALID] Time Left: 0.00 | Epoch: [   5/120] | Valid Loss: 5.0189 | Valid F1: 0.0667%\n","[TRAIN] Elapsed time: 0:00:00.478975 | Epoch: [   6/120] | step:    1/107 | Train Loss: 0.0319\n","[TRAIN] Elapsed time: 0:00:00.538247 | Epoch: [   6/120] | step:   31/107 | Train Loss: 1.0073\n","[TRAIN] Elapsed time: 0:00:00.605200 | Epoch: [   6/120] | step:   61/107 | Train Loss: 1.9598\n","[TRAIN] Elapsed time: 0:00:00.426248 | Epoch: [   6/120] | step:   91/107 | Train Loss: 2.9019\n","[VALID] Time Left: 0.00 | Epoch: [   6/120] | Valid Loss: 5.3457 | Valid F1: 0.1532%\n","[TRAIN] Elapsed time: 0:00:00.806004 | Epoch: [   7/120] | step:    1/107 | Train Loss: 0.0330\n","[TRAIN] Elapsed time: 0:00:00.459497 | Epoch: [   7/120] | step:   31/107 | Train Loss: 0.9491\n","[TRAIN] Elapsed time: 0:00:00.419719 | Epoch: [   7/120] | step:   61/107 | Train Loss: 1.8650\n","[TRAIN] Elapsed time: 0:00:00.468008 | Epoch: [   7/120] | step:   91/107 | Train Loss: 2.7718\n","[VALID] Time Left: 0.00 | Epoch: [   7/120] | Valid Loss: 5.3747 | Valid F1: 0.1949%\n","[TRAIN] Elapsed time: 0:00:00.513375 | Epoch: [   8/120] | step:    1/107 | Train Loss: 0.0307\n","[TRAIN] Elapsed time: 0:00:00.411341 | Epoch: [   8/120] | step:   31/107 | Train Loss: 0.9238\n","[TRAIN] Elapsed time: 0:00:00.419000 | Epoch: [   8/120] | step:   61/107 | Train Loss: 1.7879\n","[TRAIN] Elapsed time: 0:00:01.035426 | Epoch: [   8/120] | step:   91/107 | Train Loss: 2.6192\n","[VALID] Time Left: 0.03 | Epoch: [   8/120] | Valid Loss: 4.9755 | Valid F1: 0.2593%\n","[TRAIN] Elapsed time: 0:00:00.724501 | Epoch: [   9/120] | step:    1/107 | Train Loss: 0.0291\n","[TRAIN] Elapsed time: 0:00:00.416245 | Epoch: [   9/120] | step:   31/107 | Train Loss: 0.8420\n","[TRAIN] Elapsed time: 0:00:00.432461 | Epoch: [   9/120] | step:   61/107 | Train Loss: 1.6489\n","[TRAIN] Elapsed time: 0:00:00.625080 | Epoch: [   9/120] | step:   91/107 | Train Loss: 2.4610\n","[VALID] Time Left: 0.00 | Epoch: [   9/120] | Valid Loss: 5.3136 | Valid F1: 0.2518%\n","[TRAIN] Elapsed time: 0:00:00.528673 | Epoch: [  10/120] | step:    1/107 | Train Loss: 0.0264\n","[TRAIN] Elapsed time: 0:00:00.549777 | Epoch: [  10/120] | step:   31/107 | Train Loss: 0.8228\n","[TRAIN] Elapsed time: 0:00:00.601915 | Epoch: [  10/120] | step:   61/107 | Train Loss: 1.5960\n","[TRAIN] Elapsed time: 0:00:00.469488 | Epoch: [  10/120] | step:   91/107 | Train Loss: 2.3219\n","[VALID] Time Left: 0.00 | Epoch: [  10/120] | Valid Loss: 5.6577 | Valid F1: 0.0363%\n","[TRAIN] Elapsed time: 0:00:00.486908 | Epoch: [  11/120] | step:    1/107 | Train Loss: 0.0215\n","[TRAIN] Elapsed time: 0:00:00.421781 | Epoch: [  11/120] | step:   31/107 | Train Loss: 0.7671\n","[TRAIN] Elapsed time: 0:00:00.647613 | Epoch: [  11/120] | step:   61/107 | Train Loss: 1.5020\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1Bk4745auW06nukihmMH_Rvrml8mtkDTX","timestamp":1720681496368}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}