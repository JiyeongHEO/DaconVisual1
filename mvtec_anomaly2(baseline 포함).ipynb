{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kCIAcX580UgX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720244187977,"user_tz":-540,"elapsed":85946,"user":{"displayName":"h지영","userId":"09931517472368185956"}},"outputId":"45a7cabf-7249-4e88-f123-920acf84af7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n","Collecting timm\n","  Downloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->timm)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 timm-1.0.7\n","Collecting torchsampler\n","  Downloading torchsampler-0.1.2-py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from torchsampler) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from torchsampler) (0.18.0+cu121)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsampler) (2.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->torchsampler) (12.5.82)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->torchsampler) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->torchsampler) (9.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->torchsampler) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->torchsampler) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->torchsampler) (1.3.0)\n","Installing collected packages: torchsampler\n","Successfully installed torchsampler-0.1.2\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","path = '/content/gdrive/Othercomputers/내 노트북/Desktop/Dacon/ComputerVIsion'\n","\n","import os\n","os.chdir(path)\n","\n","!pip install timm\n","!pip install torchsampler"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"jMI_krt-14A9","executionInfo":{"status":"ok","timestamp":1720244221291,"user_tz":-540,"elapsed":3,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","from glob import glob\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import cv2\n","\n","import os\n","import timm\n","import random\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from sklearn.metrics import f1_score, accuracy_score\n","import time\n","from torchsampler.imbalanced import ImbalancedDatasetSampler\n","\n","device = torch.device('cuda')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ibHSA4Lz191r","executionInfo":{"status":"ok","timestamp":1720244221292,"user_tz":-540,"elapsed":3,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"outputs":[],"source":["train_png = sorted(glob('open/train/*.png'))\n","test_png = sorted(glob('open/test/*.png'))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FRixla4a2VfI","executionInfo":{"status":"ok","timestamp":1720244221996,"user_tz":-540,"elapsed":707,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"outputs":[],"source":["train_y = pd.read_csv(\"open/train_df.csv\")\n","\n","train_labels = train_y[\"label\"]\n","\n","label_unique = sorted(np.unique(train_labels))\n","label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n","\n","train_labels = [label_unique[k] for k in train_labels]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-EbfENe2VfI"},"outputs":[],"source":["def img_load(path):\n","    img = cv2.imread(path)[:,:,::-1]\n","    img = cv2.resize(img, (512, 512))\n","    return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XhUJ0UDC2VfJ"},"outputs":[],"source":["train_imgs = [img_load(m) for m in tqdm(train_png)]\n","test_imgs = [img_load(n) for n in tqdm(test_png)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywi_UHuh2VfJ","colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"status":"error","timestamp":1720172839593,"user_tz":-540,"elapsed":336,"user":{"displayName":"h지영","userId":"09931517472368185956"}},"outputId":"ec25b25c-17e5-48ce-d6c5-f95c8fa9f6bc"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-676bf5f2be60>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustom_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"]}],"source":["class Custom_dataset(Dataset):\n","    def __init__(self, img_paths, labels, mode='train'):\n","        self.img_paths = img_paths\n","        self.labels = labels\n","        self.mode=mode\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img = self.img_paths[idx]\n","\n","        if self.mode=='train':\n","            augmentation = random.randint(0,2)\n","            if augmentation==1:\n","                img = img[::-1].copy()\n","            elif augmentation==2:\n","                img = img[:,::-1].copy()\n","\n","        img = transforms.ToTensor()(img)\n","        if self.mode=='test':\n","            pass\n","\n","        label = self.labels[idx]\n","        return img, label\n","\n","    def get_labels(self):\n","        return self.labels\n","\n","\n","class Network(nn.Module):\n","    def __init__(self):\n","        super(Network, self).__init__()\n","        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=88)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dR7bKOh2VfJ","colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"status":"error","timestamp":1720172834275,"user_tz":-540,"elapsed":333,"user":{"displayName":"h지영","userId":"09931517472368185956"}},"outputId":"df2b41df-f879-4ceb-be66-25a07227a511"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Custom_dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ecf9c75e95dc>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustom_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m train_loader = DataLoader(train_dataset, batch_size=batch_size,\n\u001b[1;32m      7\u001b[0m                           sampler=ImbalancedDatasetSampler(train_dataset))\n","\u001b[0;31mNameError\u001b[0m: name 'Custom_dataset' is not defined"]}],"source":["batch_size = 32\n","epochs = 120\n","\n","# Train\n","train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n","train_loader = DataLoader(train_dataset, batch_size=batch_size,\n","                          sampler=ImbalancedDatasetSampler(train_dataset))\n","\n","# Test\n","test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n","\n","\n","def score_function(real, pred):\n","    score = f1_score(real, pred, average=\"macro\")\n","    return score\n"]},{"cell_type":"markdown","metadata":{"id":"vTchC4Gg2VfJ"},"source":["# ImbalancedSampler Debugging"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"Kc2lRc5o2VfJ","executionInfo":{"status":"error","timestamp":1719747551511,"user_tz":-540,"elapsed":308,"user":{"displayName":"h지영","userId":"09931517472368185956"}},"outputId":"ef2af8bc-392f-471b-eafc-730c39cd970d"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_loader' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-ce80f95fa3a7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"open/train_df.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# print(sample_data)\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"]}],"source":["# ImbalancedSampler Debugging ------------------------------------\n","invert_label_unique = {value:key for key, value in label_unique.items()}\n","df = pd.read_csv(\"open/train_df.csv\")\n","\n","for idx, sample_data in enumerate(train_loader): # batch_size 만큼 [이미지:label]튜플 불러옴\n","    if idx == 1: break\n","    # print(sample_data)\"\"\n","    x = torch.tensor(sample_data[0], dtype=torch.float32, device=device)\n","    y = torch.tensor(sample_data[1], dtype=torch.long, device=device)\n","\n","    label_names = []\n","    print(f\"{'sampled sample_data label':<30} | {'Total Count'}\")\n","    print(\"-\" * 50)\n","    for sample in y:\n","        sample = sample.item() # tensor 스칼라 값을 Python의 기본 자료형(예: int, float)으로 변환\n","        label_name = invert_label_unique[sample]\n","        label_names.append(label_name)\n","\n","        sampled_label_cnt = len(df[df['label'] == label_name]) # 'label' 열에서 label_name과 같은 행의 갯수\n","        print(f\"{label_name:<30} | {sampled_label_cnt:>10}\") # :<30 왼쪽 정렬,최소 30자리 공간을 차지\n","    print(label_names)\n","    print(y)\n","# ---------------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdrDbOdH2VfK"},"outputs":[],"source":["model = Network().to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss()\n","scaler = torch.cuda.amp.GradScaler()\n","\n","\n","best=0\n","train_f1_list = []\n","for epoch in range(epochs):\n","    start=time.time()\n","    train_loss = 0\n","    train_pred=[]\n","    train_y=[]\n","    model.train()\n","    for batch in (train_loader):\n","        optimizer.zero_grad()\n","        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n","        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n","        with torch.cuda.amp.autocast():\n","            pred = model(x)\n","        loss = criterion(pred, y)\n","\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        train_loss += loss.item()/len(train_loader)\n","        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n","        train_y += y.detach().cpu().numpy().tolist()\n","\n","\n","    train_f1 = score_function(train_y, train_pred)\n","    train_f1_list.append(train_f1)\n","    # print(train_f1_list)\n","    if max(train_f1_list) > train_f1_list[-1]:\n","        torch.save(model.state_dict(), \"./model/\"+str(epoch)+\".pt\")\n","\n","    TIME = time.time() - start\n","    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n","    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n"]},{"cell_type":"markdown","source":["[BASELINE] EfficientNet_b0을 활용한 분류 모델[public:0.67091]"],"metadata":{"id":"saI9GBU73KZd"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"3qmVwNP-6Y4L"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"MOdWbI7T6Yyx"}},{"cell_type":"markdown","source":["\n","\n","---\n"],"metadata":{"id":"9estI3nK6YsH"}},{"cell_type":"markdown","source":["### 라이브러리 로드"],"metadata":{"id":"yYUmCd6b6QN1"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","from glob import glob\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import cv2\n","\n","import os\n","import timm\n","import random\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from sklearn.metrics import f1_score, accuracy_score\n","import time\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 장치 설정: GPU가 사용 가능한 경우 'cuda', 그렇지 않으면 'cpu'"],"metadata":{"id":"wtq8XpHQ3JJh","executionInfo":{"status":"ok","timestamp":1720244194491,"user_tz":-540,"elapsed":6524,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### 데이터로드1 - png파일 load\n"],"metadata":{"id":"uKOVnqnD6cfS"}},{"cell_type":"code","source":["train_png = sorted(glob('open/train/*.png'))\n","test_png = sorted(glob('open/test/*.png'))\n","print(len(train_png))\n","print(len(test_png))"],"metadata":{"id":"nDBGWnGH3WWX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720244221291,"user_tz":-540,"elapsed":26811,"user":{"displayName":"h지영","userId":"09931517472368185956"}},"outputId":"226d7bf1-851f-4830-bae8-778c34be2b8f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["4277\n","2154\n"]}]},{"cell_type":"markdown","source":["### 데이터로드1 - train_df.csv 파일 로드 후 label 인덱스화"],"metadata":{"id":"BcRnNBom8B3T"}},{"cell_type":"code","source":["train_y = pd.read_csv(\"open/train_df.csv\")\n","train_labels = train_y[\"label\"]\n","\n","label_unique = sorted(np.unique(train_labels))\n","\n","label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))} #zip: 두 배열 matching -> dictionary구조로(라벨:숫자)\n","\n","train_labels = [label_unique[k] for k in train_labels] # train_labels를 인덱스로 변환\n"],"metadata":{"id":"HQtORh_73bkg","executionInfo":{"status":"ok","timestamp":1720244254778,"user_tz":-540,"elapsed":529,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### 데이터로드2 - img_load() 정의 및 로드"],"metadata":{"id":"73-K0PprB6Uv"}},{"cell_type":"code","source":["def img_load(path):\n","    #OpenCV -> Numpy배열(height, width, 색상채널. 보통 BGR)\n","    img = cv2.imread(path)[:,:,::-1] #:모든요소, 모든요소, ::-1 색상채널 순서를 뒤집는다(RGB로)\n","    img = cv2.resize(img, (512, 512))\n","    return img"],"metadata":{"id":"D2mG8T-a3d2p","executionInfo":{"status":"ok","timestamp":1720244255944,"user_tz":-540,"elapsed":565,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 이미지 로딩\n","# train_imgs = [img_load(m) for m in tqdm(train_png)]\n","# test_imgs = [img_load(n) for n in tqdm(test_png)]\n","\n","train_imgs = []  #tqdm: 로딩상황 시각적확인  (List Comprehension일때 줄나눔있어서 변경) 2.37\n","for m in tqdm(train_png):\n","    train_imgs.append(img_load(m))\n","test_imgs = []\n","for n in tqdm(test_png):\n","    test_imgs.append(img_load(n))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aAEJ2Tg-3fjt","outputId":"13d4eaee-e2f9-496e-8312-6a14e7ad20e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4277/4277 [10:23<00:00,  6.86it/s]\n","  7%|▋         | 156/2154 [03:52<47:04,  1.41s/it]"]}]},{"cell_type":"markdown","source":["### 데이터로드3 - Custom_dataset() 정의  \n","### Custom_dataset2() + ProcessedDataset() 정의 - train_dataset파일 생성용"],"metadata":{"id":"93els-TZyjbk"}},{"cell_type":"code","source":["#[JAVA] Class: 속성, 생성자, 메소드 /  접근제어자 O / 다중상속x interface통해가능 / 메소드오버로딩 O\n","#[Python] 생성자, 메소드 /  밑줄 / 다중상속 O / 메소드오버로딩X / class외부에서 동적 속성,메소드 추가 가능\n","class Custom_dataset(Dataset):\n","    def __init__(self, img_paths, labels, mode='train'):\n","        self.img_paths = img_paths\n","        self.labels = labels\n","        self.mode=mode\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img = self.img_paths[idx]\n","        if self.mode=='train':\n","            augmentation = random.randint(0,2)\n","            if augmentation==1:\n","                img = img[::-1].copy() #좌우반전, 새로운배열\n","            elif augmentation==2:\n","                img = img[:,::-1].copy() #상하반전, \"\"\n","\n","        img = transforms.ToTensor()(img) # 1.PyTorch텐서로 변환(모델입력되게) 2. 0~255 값을 0~1사이 정규화 자동수행\n","        if self.mode=='test':\n","            pass\n","\n","        label = self.labels[idx]\n","        return img, label\n"],"metadata":{"id":"LG9UL7BH3nOt","executionInfo":{"status":"ok","timestamp":1720243971918,"user_tz":-540,"elapsed":1,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class Custom_dataset2(Dataset):\n","    def __init__(self, imgs, labels, mode='train', save_path='processed_data/train_dataset.pt'):\n","        self.imgs = imgs\n","        self.labels = labels\n","        self.mode = mode\n","        self.save_path = save_path\n","        os.makedirs(os.path.dirname(self.save_path), exist_ok=True)\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","\n","    def __getitem__(self, idx):\n","        img = self.imgs[idx]\n","        label = self.labels[idx]\n","\n","        if self.mode == 'train':\n","            augmentation = random.randint(0, 2)\n","            if augmentation == 1:\n","                img = img[::-1].copy()  # 좌우 반전\n","            elif augmentation == 2:\n","                img = img[:, ::-1].copy()  # 상하 반전\n","\n","        img_tensor = transforms.ToTensor()(img)  # PyTorch 텐서로 변환\n","\n","        return img_tensor, label\n","\n","    def save_processed_data(self):\n","        all_data = []\n","        for idx in range(len(self.imgs)):\n","            img_tensor, label = self.__getitem__(idx)\n","            all_data.append((img_tensor, label))\n","        torch.save(all_data, self.save_path)\n"],"metadata":{"id":"d9eOhVwrRQCN","executionInfo":{"status":"ok","timestamp":1720243975242,"user_tz":-540,"elapsed":368,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class ProcessedDataset(Dataset):\n","    def __init__(self, data_path='processed_data/train_dataset.pt'):\n","        self.data = torch.load(data_path)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_tensor, label = self.data[idx]\n","        return img_tensor, label"],"metadata":{"id":"QK_VR0grZ_WU","executionInfo":{"status":"ok","timestamp":1720243978922,"user_tz":-540,"elapsed":344,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### 모델 정의"],"metadata":{"id":"Q-VGXGzf_PsK"}},{"cell_type":"code","source":["class Network(nn.Module):  #pyTorch의 nn,Module을 상속받아 새로운 신경망 모듈 Network를 정의\n","    def __init__(self):\n","        super(Network, self).__init__()  #부모class(nn,Module)의 생성자 호출 -> 초기화\n","        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=88) #timm - PyTorch용 다양한 이미지 분류 모델을 제공하는 라이브러리\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"metadata":{"id":"saS418Jp_PHr","executionInfo":{"status":"ok","timestamp":1720243984335,"user_tz":-540,"elapsed":375,"user":{"displayName":"h지영","userId":"09931517472368185956"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["### 데이터로드4 : pyTorch텐서로 변환 ->"],"metadata":{"id":"saXJy2YJB0JE"}},{"cell_type":"code","source":["batch_size = 32\n","epochs = 25\n","\n","# Train 1\n","# train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train') #train_imgs는 이미 numPy배열이라 불필요? (아마 데이터형식 명확히 or 복사본 필요) / 리턴: pyTorch의 Tensor\n","# train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size) #배치단위로 묶어서 로드.Torch.Tensor(배치크기, 채널 색상, height, width) / 마지막 배치는 다를수있음(나누어떨어지지않으면..)\n","\n","# Train 2 - pt파일로 train_dataset가져올때\n","train_dataset = Custom_dataset2(np.array(train_imgs), np.array(train_labels), mode='train')\n","train_dataset.save_processed_data() # 생성 및 저장\n","processed_train_dataset = ProcessedDataset(data_path='processed_data/train_dataset.pt')  #불러오기\n","data_loader = DataLoader(processed_train_dataset, shuffle=True, batch_size=batch_size)\n","#Train2 끝\n","\n","\n","# Test 1\n","# test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n","# test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n","\n","# Test 2 - pt파일로 train_dataset가져올때\n","test_dataset = Custom_dataset2(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n","test_dataset.save_processed_data() # 생성 및 저장\n","processed_test_dataset = ProcessedDataset(data_path='processed_data/train_dataset.pt')  #불러오기\n","test_loader = DataLoader(processed_test_dataset, shuffle=False, batch_size=batch_size)\n","# Test 2 끝"],"metadata":{"id":"fm7SELvt3o-b","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"error","timestamp":1720244017086,"user_tz":-540,"elapsed":356,"user":{"displayName":"h지영","userId":"09931517472368185956"}},"outputId":"33e8d842-9601-4055-cd67-15cee5bc846d"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Custom_dataset2' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4f6a427cda01>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Train 2 - pt파일로 train_dataset가져올때\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustom_dataset2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_processed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 생성 및 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprocessed_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessedDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'processed_data/train_dataset.pt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Custom_dataset2' is not defined"]}]},{"cell_type":"markdown","source":["# **모델 학습**"],"metadata":{"id":"EG-RuSuq3qze"}},{"cell_type":"code","source":["def score_function(real, pred):\n","    score = f1_score(real, pred, average=\"macro\") #'macro 평균'은 각 클래스에 대해 F1 점수를 개별적으로 계산한 후, 모든 클래스의 F1 점수의 단순 평균을\n","    return score\n","\n","model = Network().to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss()\n","scaler = torch.cuda.amp.GradScaler()\n","\n","\n","best=0\n","for epoch in range(epochs):\n","    start=time.time()\n","    train_loss = 0\n","    train_pred=[]\n","    train_y=[]\n","    model.train()\n","    for batch in (train_loader):\n","        optimizer.zero_grad()\n","        x = torch.tensor(batch[0], dtype=torch.float32, device=device) # (배치크기, 채널, h, w) 형태의 텐서(이미지)\n","        y = torch.tensor(batch[1], dtype=torch.long, device=device) # (배치크기,)형태의 텐서type으로 변환(정답값)\n","        with torch.cuda.amp.autocast():  # AMP(Auto Mixed Precision) 모듈 + 모든 연산은 자동으로 적절한 정밀도로 변환됩니다. 주로 GPU 연산, 작은 물컵.\n","            pred = model(x)\n","        loss = criterion(pred, y) #손실함수(모델이 얼마나 틀렸는지 계산)\n","\n","        # 손실값을 적당히 크게 해서 계산 (언더플로우 방지)\n","        scaler.scale(loss).backward() #역전파: 다시 예측할때 필요한 지우개\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        train_loss += loss.item()/len(train_loader) #학습하면서 바로바로 평균손실 계산\n","        train_pred += pred.argmax(1).detach().cpu().numpy().tolist() #pred.argmax(1)는 모델이 예측한 값 중 가장 높은 확률을 가진 값을 선택 #모델이 여러 사진에 대해 예측한 결과를 모두 리스트에 모아두고, 나중에 한 번에 확인할 수 있다\n","        train_y += y.detach().cpu().numpy().tolist() # detach()를 사용해서 계산 그래프에서 분리, 나중에 역전파(backpropagation)할 때 영향을 받지 않는다.\n","        #train_y는 detach()가 y에 필요하지 않다던데..?;\n","        # cpu().numpy().tolist(): 텐서는 GPU연산가능, 파이썬은 불가.\n","\n","    train_f1 = score_function(train_y, train_pred) #파이썬or NumPy배열 필요, return score\n","\n","    TIME = time.time() - start\n","    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n","    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"T79_Wnff3uOL","executionInfo":{"status":"error","timestamp":1719751899436,"user_tz":-540,"elapsed":4,"user":{"displayName":"h지영","userId":"09931517472368185956"}},"outputId":"b4108cac-4eb5-4eac-8326-c3eb5cad0738"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Network' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4c3fa9376b9b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Network' is not defined"]}]},{"cell_type":"markdown","source":["# **추론**"],"metadata":{"id":"EeO-_wTJMgKS"}},{"cell_type":"code","source":["model.eval()\n","f_pred = []\n","\n","with torch.no_grad():\n","    for batch in (test_loader):\n","        x = torch.tensor(batch[0], dtype = torch.float32, device = device) #batch[0]: 튜플의1st. 이미지\n","        with torch.cuda.amp.autocast(): # PyTorch의 자동 혼합 정밀도(Automatic Mixed Precision)를 활성화\n","            pred = model(x)\n","        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist()) #모델의 '예측 결과' pred에서 가장 높은 값을 가지는 클래스 인덱스를 반환합니다\n","        # -> 그래디언트 계산을 추적하지 않도록 텐서를 분리 ->  CPU로 이동합니다. numpy 배열로 변환하기 위해 -> Python 리스트로 변환"],"metadata":{"id":"AsTrIIKzMigp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_decoder = {val:key for key, val in label_unique.items()} # 모든 (키, 값)을 튜플의 리스트로 반환\n","\n","f_result = [label_decoder[result] for result in f_pred]"],"metadata":{"id":"232VLoVKM8lC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **제출물 생성**"],"metadata":{"id":"iJVAVmnCM-dj"}},{"cell_type":"code","source":["submission = pd.read_csv(\"open/sample_submission.csv\")\n","\n","submission[\"label\"] = f_result\n","\n","submission"],"metadata":{"id":"hIDiXv48NAWj"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}