{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85946,"status":"ok","timestamp":1720244187977,"user":{"displayName":"h지영","userId":"09931517472368185956"},"user_tz":-540},"id":"kCIAcX580UgX","outputId":"45a7cabf-7249-4e88-f123-920acf84af7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive/\n","Collecting timm\n","  Downloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->timm)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 timm-1.0.7\n","Collecting torchsampler\n","  Downloading torchsampler-0.1.2-py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from torchsampler) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from torchsampler) (0.18.0+cu121)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsampler) (2.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->torchsampler) (12.5.82)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->torchsampler) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->torchsampler) (9.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->torchsampler) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->torchsampler) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->torchsampler) (1.3.0)\n","Installing collected packages: torchsampler\n","Successfully installed torchsampler-0.1.2\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","path = '/content/gdrive/Othercomputers/내 노트북/Desktop/Dacon/ComputerVIsion'\n","\n","import os\n","os.chdir(path)\n","\n","!pip install timm\n","!pip install torchsampler"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import random\n","import numpy as np\n","import pandas as pd\n","import os.path as osp\n","import torchvision.transforms as transforms\n","\n","from glob import glob\n","from torch.utils.data import Dataset\n","from torchvision.transforms import functional as F\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class mvtecDatasetPreprocess:\n","    def __init__(self, data_dir, mode='train'):\n","        if mode == 'train':\n","            self.image_paths = glob(osp.join(data_dir, mode, \"*.png\"))\n","            csv_path         = osp.join(data_dir, 'train_df.csv')\n","            self.labels      = self.read_label_csv(csv_path)\n","        \n","        elif mode == 'test':\n","            self.image_paths  = glob(osp.join(data_dir, mode, '*.png'))\n","        \n","        \n","    def read_label_csv(self, csv_path):\n","        train_csv = pd.read_csv(csv_path)\n","        \n","        train_labels = train_csv['label']\n","        label_unique = sorted(np.unique(train_labels))\n","        label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n","\n","        train_labels = [label_unique[k] for k in train_labels]\n","        \n","        return train_labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class mvtecDataset(Dataset):\n","    def __init__(self, image_paths, labels, mode='train'):\n","        self.image_paths = image_paths\n","        self.labels      = labels\n","        self.mode        = mode\n","        \n","        \n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        \n","        image = Image.open(image_path).convert('RGB')\n","\n","        # 데이터 증강\n","        if self.mode=='train':\n","            data_transforms = transforms.Compose([\n","                transforms.RandomHorizontalFlip(),             \n","                transforms.RandomVerticalFlip(),               \n","                transforms.RandomRotation(45),                 \n","                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n","                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  \n","                transforms.RandomResizedCrop(512),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","            \n","            image = data_transforms(image)\n","        \n","        if self.mode=='test':\n","            pass\n","\n","        label = self.labels[idx]\n","        \n","        return image, label\n","\n","\n","    def get_labels(self):\n","        return self.labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","import os\n","import os.path as osp\n","sys.path.append(osp.join(os.getcwd(), \"test\"))\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import timm\n","import random\n","import time\n","import torch\n","import torch.nn as nn\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import f1_score\n","from torch.utils.data import DataLoader, Subset\n","from torchsampler.imbalanced import ImbalancedDatasetSampler\n","#from mvtec_anomaly_dataloader import mvtecDatasetPreprocess, mvtecDataset\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime"]},{"cell_type":"markdown","metadata":{"id":"vTchC4Gg2VfJ"},"source":["# ImbalancedSampler Debugging"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":308,"status":"error","timestamp":1719747551511,"user":{"displayName":"h지영","userId":"09931517472368185956"},"user_tz":-540},"id":"Kc2lRc5o2VfJ","outputId":"ef2af8bc-392f-471b-eafc-730c39cd970d"},"outputs":[{"ename":"NameError","evalue":"name 'train_loader' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-ce80f95fa3a7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"open/train_df.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# print(sample_data)\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"]}],"source":["def debugging_ImbalancedSampler(label_unique, train_loader, device):\n","    # ImbalancedSampler Debugging ------------------------------------\n","    invert_label_unique = {value:key for key, value in label_unique.items()}\n","    df = pd.read_csv(\"open/train_df.csv\")\n","\n","    for idx, sample_data in enumerate(train_loader):\n","        if idx == 1: break\n","        # print(sample_data)\"\"\n","        x = torch.tensor(sample_data[0], dtype=torch.float32, device=device)\n","        y = torch.tensor(sample_data[1], dtype=torch.long, device=device)\n","        \n","        label_names = []\n","        print(f\"{'sampled sample_data label':<30} | {'Total Count'}\")\n","        print(\"-\" * 50)\n","        for sample in y:\n","            sample = sample.item()\n","            label_name = invert_label_unique[sample]\n","            label_names.append(label_name)\n","\n","            sampled_label_cnt = len(df[df['label'] == label_name])\n","            print(f\"{label_name:<30} | {sampled_label_cnt:>10}\")\n","        print(label_names)\n","        print(y)\n","    # ---------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{"id":"saI9GBU73KZd"},"source":["[BASELINE] EfficientNet_b0을 활용한 분류 모델[public:0.67091]"]},{"cell_type":"markdown","metadata":{"id":"3qmVwNP-6Y4L"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MOdWbI7T6Yyx"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9estI3nK6YsH"},"source":["\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"yYUmCd6b6QN1"},"source":["### 라이브러리 로드"]},{"cell_type":"markdown","metadata":{"id":"uKOVnqnD6cfS"},"source":["### 데이터로드1 - png파일 load\n"]},{"cell_type":"markdown","metadata":{"id":"BcRnNBom8B3T"},"source":["### 데이터로드1 - train_df.csv 파일 로드 후 label 인덱스화"]},{"cell_type":"markdown","metadata":{"id":"73-K0PprB6Uv"},"source":["### 데이터로드2 - img_load() 정의 및 로드"]},{"cell_type":"markdown","metadata":{"id":"93els-TZyjbk"},"source":["### 데이터로드3 - Custom_dataset() 정의  \n","### Custom_dataset2() + ProcessedDataset() 정의 - train_dataset파일 생성용"]},{"cell_type":"markdown","metadata":{"id":"Q-VGXGzf_PsK"},"source":["### 모델 정의"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":375,"status":"ok","timestamp":1720243984335,"user":{"displayName":"h지영","userId":"09931517472368185956"},"user_tz":-540},"id":"saS418Jp_PHr"},"outputs":[],"source":["class Network(nn.Module):  #pyTorch의 nn,Module을 상속받아 새로운 신경망 모듈 Network를 정의\n","    def __init__(self):\n","        super(Network, self).__init__()  #부모class(nn,Module)의 생성자 호출 -> 초기화\n","        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=88) #timm - PyTorch용 다양한 이미지 분류 모델을 제공하는 라이브러리\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"saXJy2YJB0JE"},"source":["### 데이터로드4 : pyTorch텐서로 변환 ->"]},{"cell_type":"markdown","metadata":{"id":"EG-RuSuq3qze"},"source":["# **모델 학습**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":4,"status":"error","timestamp":1719751899436,"user":{"displayName":"h지영","userId":"09931517472368185956"},"user_tz":-540},"id":"T79_Wnff3uOL","outputId":"b4108cac-4eb5-4eac-8326-c3eb5cad0738"},"outputs":[{"ename":"NameError","evalue":"name 'Network' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4c3fa9376b9b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Network' is not defined"]}],"source":["# 파라미터 셋팅\n","batch_size = 32\n","num_epochs = 120\n","learning_rate = 1e-3\n","folds = 5\n","\n","# GPU 셋팅\n","if torch.cuda.is_available():\n","    device = torch.device(f'cuda:{0}')\n","    print(\"Use GPU: {} for training\".format(0))\n","else:\n","    device = torch.device('cpu')\n","    print('Use CPU')\n","\n","\n","# data_dir  = osp.join(osp.dirname(__file__), 'open') # NameError: name '__file__' is not defined\n","# model_dir = osp.join(osp.dirname(__file__), 'experiments', 'models')\n","# log_dir   = osp.join(osp.dirname(__file__), 'experiments', 'logs')\n","current_dir = os.getcwd()\n","data_dir  = os.path.join(current_dir, 'open')\n","model_dir = os.path.join(current_dir, 'experiments', 'models')\n","log_dir   = os.path.join(current_dir, 'experiments', 'logs')\n","\n","    \n","# 폴더 존재 점검\n","if not osp.exists(model_dir):\n","    os.makedirs(model_dir)\n","if not osp.exists(log_dir):\n","    os.makedirs(log_dir)\n","\n","# 텐서보드 셋팅\n","writer = SummaryWriter(log_dir)\n","\n","# 학습 데이터\n","preprocessor = mvtecDatasetPreprocess(data_dir, mode='train')\n","\n","# # 테스트 데이터\n","# test_dataset = mvtecDataset(data_dir, mode='test')\n","# test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# 교차검증\n","kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state = 1)\n","for fold, (indices_train, indices_valid) in enumerate(kfold.split(preprocessor.image_paths, preprocessor.labels)):\n","    subset_train_image_paths = [preprocessor.image_paths[idx] for idx in indices_train]\n","    subset_train_labels      = [preprocessor.labels[idx] for idx in indices_train]\n","    \n","    subset_valid_image_paths = [preprocessor.image_paths[idx] for idx in indices_valid]\n","    subset_valid_labels      = [preprocessor.labels[idx] for idx in indices_valid]\n","    \n","    train_subset = mvtecDataset(subset_train_image_paths, subset_train_labels)\n","    valid_subset = mvtecDataset(subset_valid_image_paths, subset_valid_labels)\n","    \n","    train_loader  = DataLoader(train_subset, batch_size=batch_size, \n","                                sampler=ImbalancedDatasetSampler(train_subset), \n","                                pin_memory=True, \n","                                num_workers=8)\n","    valid_loader  = DataLoader(valid_subset, batch_size=batch_size, \n","                                shuffle=False, \n","                                pin_memory=True, \n","                                num_workers=8)\n","        \n","# 모델 정의\n","model = Network().to(device)\n","\n","# 최적화\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","scaler = torch.cuda.amp.GradScaler()\n","\n","# ------------------------------------ 학습 ------------------------------------ \n","total_train_steps   = torch.tensor(len(train_loader), dtype=torch.int32, device=device)\n","total_valid_steps   = torch.tensor(len(valid_loader), dtype=torch.int32, device=device)\n","for epoch in range(num_epochs):\n","    start = time.time()\n","    \n","    train_loss = torch.zeros(1,     device=device)\n","    model.train()\n","    for train_step, (sample_image, sample_label) in enumerate(train_loader):\n","        # if train_step > 1: break\n","        start = datetime.now()\n","\n","        optimizer.zero_grad()\n","        sample_image = torch.tensor(sample_image, dtype=torch.float32, device=device)\n","        sample_label = torch.tensor(sample_label, dtype=torch.long,    device=device)\n","        \n","        with torch.cuda.amp.autocast():\n","            pred = model(sample_image)\n","            loss = criterion(pred, sample_label)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        \n","        train_loss += torch.div(loss, total_train_steps)\n","        \n","        \"\"\"\n","        (a1 + a2 + ... + a100) / 100 = 평균\n","        a1/100 + a2/100 + .... + a100/100 = 평균\n","        \"\"\"\n","        \n","        elapsed_time = datetime.now() - start\n","        if train_step % 30 == 0:\n","            print(f\"[TRAIN] Elapsed time: {elapsed_time} | Epoch: [{epoch + 1:>4}/{num_epochs}] | step: {train_step+1:>4}/{len(train_loader)} | Train Loss: {train_loss.tolist()[0]:4.4f}\")\n","    \n","    # ------------------------------------------------------------------------------\n","    \n","    # ------------------------------------ 검증 ------------------------------------\n","    valid_loss    = torch.zeros(1,   device=device)\n","    valid_f1      = 0\n","    valid_f1_list = []\n","    model.eval()\n","    for sample_image, sample_label in valid_loader:\n","        start = datetime.now()\n","        \n","        sample_image = torch.tensor(sample_image, dtype=torch.float32, device=device)\n","        sample_label = torch.tensor(sample_label, dtype=torch.long,    device=device)\n","        \n","        with torch.no_grad():\n","            with torch.cuda.amp.autocast():\n","                pred = model(sample_image)\n","                loss = criterion(pred, sample_label)\n","        \n","        valid_loss += torch.div(loss, total_valid_steps)\n","        \n","        valid_pred  = pred.argmax(1).detach().cpu().numpy().tolist()\n","        sample_label = sample_label.detach().cpu().numpy().tolist()\n","\n","        valid_f1 += (f1_score(sample_label, valid_pred, average=\"macro\") / len(valid_loader))\n","        valid_f1_list.append(valid_f1)\n","        \n","        \n","    if len(valid_f1_list) > 1 and (valid_f1 > max(valid_f1_list[:-1])):\n","        torch.save(model.state_dict(), osp.join(model_dir, f'fold_{fold:02d}-epoch_{epoch:03d}.pth'))\n","    \n","    elapsed_time = datetime.now() - start\n","    time_left = ((num_epochs - epoch+1) * elapsed_time.seconds) / 3600\n","    print(f\"[VALID] Time Left: {time_left:4.2f} | Epoch: [{epoch + 1:>4}/{num_epochs}] | Valid Loss: {valid_loss.tolist()[0]:4.4f} | Valid F1: {valid_f1_list[-1]*100:.4f}%\")\n","    \n","    # 텐서보드\n","    writer.add_scalar('Loss/Train Loss', train_loss.tolist()[0], global_step=epoch)\n","    writer.add_scalar('Loss/Valid Loss', valid_loss.tolist()[0], global_step=epoch)"]},{"cell_type":"markdown","metadata":{"id":"EeO-_wTJMgKS"},"source":["# **추론**"]},{"cell_type":"markdown","metadata":{"id":"iJVAVmnCM-dj"},"source":["# **제출물 생성**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIDiXv48NAWj"},"outputs":[],"source":["submission = pd.read_csv(\"open/sample_submission.csv\")\n","\n","submission[\"label\"] = f_result\n","\n","submission"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
